import SpeechRecognition, { useSpeechRecognition } from "react-speech-recognition";
import { useState } from "react";
import { parseVoiceCommand } from "../utils/parseVoice";
import { useTasks } from "../context/TaskContext";
import audiowaves from '../assets/images/audio-waves.png'
import TaskCreate from "./TaskCreate";

export default function VoiceInput() {
const { transcript, listening, resetTranscript } = useSpeechRecognition();
const { createTask } = useTasks();

function toLocalInputValue(date) {
const d = new Date(date);
d.setMinutes(d.getMinutes() - d.getTimezoneOffset());
return d.toISOString().slice(0, 16);
}



const [parsed, setParsed] = useState(null);

const [hasParsed, setHasParsed] = useState(false);

const handleStart = () => {
setHasParsed(false);
SpeechRecognition.startListening({ continuous: true })
}

const handleStop = () => {
SpeechRecognition.stopListening();

if (!transcript || transcript.trim().length === 0) {
alert("No voice input detected. Please speak before stopping.");
return;
}

const data = parseVoiceCommand(transcript);
setParsed(data);
setHasParsed(true);
};


const updateField = (field, value) => {
setParsed({ ...parsed, [field]: value });
};

const saveTask = () => {
// Validate required field(s)
if (!parsed?.title || !parsed.title.trim()) {
alert("Please provide a title for the task before saving.");
return;
}
createTask(parsed);
setParsed(null);
setHasParsed(false);
resetTranscript();
};

return (
<div className="flex items-center justify-center flex-col gap-8">
<h2 className=" text-2xl">Here, I can help you to track tasks using your voice, Press and Hold to start create your Task.</h2>

<div className="flex items-center gap-8">

<button onClick={handleStart} className="w-20 h-20 rounded-full flex items-center justify-center shadow-md shadow-slate-900 cursor-pointer" style={{ backgroundImage: 'linear-gradient(180deg, #130214 30%, #34227E 100%)'}}>
{listening ?
<img src={audiowaves} className="w-[60px] h-[60px]"/> : <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="#fff" class="size-8">
<path stroke-linecap="round" stroke-linejoin="round" d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 0 1-3-3V4.5a3 3 0 1 1 6 0v8.25a3 3 0 0 1-3 3Z" />
</svg>}


</button>

<button onClick={handleStop} className="rounded-xl py-3 px-6 font-semibold cursor-pointer shadow-md" style={{ backgroundImage: 'linear-gradient(45deg, #D71295 20%, #34227E 80%)'}}>
Stop & Parse
</button>





</div>



<div>
{listening ? (
<div className="text-center">
<p className="mb-3">Microphone is <span className="text-red-400 font-semibold">ON</span></p>
<p><b>Task:</b> {transcript}</p>
</div>
) : (
<div className="text-center">
<p>Microphone is <span className="text-red-400 font-semibold">OFF</span></p>
{transcript ?   <p><b>Task:</b> {transcript}</p>: ''}
</div>

)}
</div>





{/* REVIEW PANEL */}
{hasParsed && (
<TaskCreate
parsed={parsed}
toLocalInputValue={toLocalInputValue}
saveTask={saveTask}
updateField={updateField}
/>
)}
</div>
);
}
